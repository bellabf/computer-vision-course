1. Image Acquisition Fundamentals in Digital Processing
Image acquisition in digital processing is a foundational step in transforming physical phenomena into digital representations. It starts with the interaction between an illumination source and the subject being imaged. This illumination can be of various types, from conventional light sources to more sophisticated forms like electromagnetic or ultrasound energy. The interaction results in energy either being reflected from or transmitted through the objects in the scene. This energy is captured by sensors, which are essentially transducers converting the incident energy into electrical voltage. The voltage signal is then digitized, resulting in a digital image. This process involves sophisticated technology and precise calibration to ensure accurate representation of the physical scene in its digital form.

2. Sensor Technologies and Their Role in Image Acquisition
In digital imaging, sensor technology is pivotal. Single sensing elements, such as photodiodes, are basic forms that require movement along both x and y axes to form a two-dimensional image. In contrast, sensor strips, which are more common, capture images linearly in one direction. To obtain a complete 2D image, these strips necessitate motion in the perpendicular direction. Such technology is commonly found in devices like flatbed scanners and is also utilized in airborne imaging systems. In more specialized applications, like medical imaging (e.g., CAT scans), ring-configured sensor strips are used. These setups involve complex reconstruction algorithms to transform the captured data into meaningful images, highlighting the advanced computation involved in modern imaging technologies. Sensor arrays, like CCDs in digital cameras, consist of 2D arrays of sensing elements. They capture a complete image without requiring motion, as each element detects part of the scene. These arrays are advantageous as they don't require movement to capture an image, unlike single sensing elements and sensor strips. The captured energy is focused onto the sensor array, converted into an analog signal, and then digitized to form a digital image.

3. Digital Image Formation and Representation
The core of digital image formation is the function f(x, y), which is determined by the illumination source i(x, y), and the reflectance r(x, y) from the scene. In transmission-based imaging, such as X-rays, transmissivity takes the place of reflectivity. The digital representation of an image is essentially a matrix or array of numerical values, each corresponding to a pixel. The process of transforming continuous image data into a digital format is twofold: sampling, which digitizes the coordinate values, and quantization, which converts amplitude values into discrete quantities. The resolution and quality of a digital image are significantly dependent on the number of samples and discrete intensity levels used. The dynamic range of the imaging system, which is the ratio of the maximum measurable intensity to the minimum detectable intensity, also plays a crucial role in the appearance and contrast of the image.

4. Understanding Resolution in Digital Imaging
Spatial resolution refers to the smallest distinguishable detail in an image and is often measured in line pairs per unit distance or pixels per unit distance. The meaningfulness of spatial resolution is context-dependent, varying according to the spatial units used. For example, a 20-megapixel camera typically offers higher detail resolution than an 8-megapixel camera. Intensity resolution relates to the smallest detectable change in intensity level and is often limited by the hardware's capabilities. It's quantized in binary increments, such as 8 bits or 256 levels. The perception of these intensity changes is influenced by various factors, including noise, saturation, and the capabilities of human vision.

5. Various Operations in Digital Image Processing
In digital image processing, operations on images are diverse and can be categorized into logical, statistical, geometrical, mathematical, and transform operations. Each category encompasses specific techniques, such as Morphology under Logical Operations and Fourier and Principal Component Analysis (PCA) under Transforms. Understanding the distinction between elementwise and matrix operations is crucial in image manipulation. Elementwise operations, such as raising an image to a power or dividing it by another image, involve processing each pixel individually. This pixel-based approach contrasts with matrix operations, which utilize matrix theory for image manipulation. You can do whatever you want images as they are matrices containing numbers!

6. Mathematical Tools in Image Processing
Mathematical tools are indispensable in digital image processing. Set theory, for instance, is crucial for understanding and performing operations on images, particularly binary images. In these images, pixels are typically categorized as either foreground (1) or background (0). Operations such as union and intersection in set theory are used to determine relationships between features represented by pixel coordinates. Intensity transformations and spatial filtering are other key mathematical tools. They focus on manipulating pixel values within an image, where operators are applied to single images or a set of images for various purposes, like noise reduction.

7. Spatial Filtering Techniques and Image Enhancement
Spatial filtering encompasses a broad range of applications in image processing, primarily focused on modifying images by altering each pixel's value based on its neighbouring pixels' values. Techniques include linear spatial filters, which can either blur (lowpass filters) or sharpen (high pass filters) an image. The properties and applications of different filter kernels, such as the Gaussian filter and box filters, are contrasted. Sharpening filters, which emphasize transitions in intensity, are often implemented through digital differentiation techniques like the Laplacian, highlighting edges and discontinuities in an image.

8. Image Restoration and Reconstruction Techniques
Image restoration focuses on objectively recovering a degraded image using knowledge about the degradation phenomenon. It often involves modelling the degradation process and applying inverse processes to regain the original image. In contrast, image enhancement is more subjective, aiming to improve the visual appearance of an image. Restoration techniques include dealing with issues like noise, which can originate from various sources during image acquisition or transmission. Advanced filters, both adaptive and non-adaptive, are explored for their noise-reduction capabilities. In the field of medical imaging, particularly in computed tomography (CT), image reconstruction from projections is a crucial application.

9. Colour in Image Processing
Colour is a powerful descriptor in image processing, playing a crucial role in object identification and recognition. Colour image processing includes both pseudo-Colour and full-Colour processing. Pseudo-Colour processing assigns Colours to grayscale intensities, while full-Colour processing uses actual Colour data from sensors. Understanding the fundamentals of Colour, including human Colour perception, the Colour spectrum, and the attributes of chromatic light, is key. Different Colour models, such as RGB for monitors and cameras and CMY/CMYK for printing, standardize Colour representation in digital imaging.
In the RGB Colour model, images comprise three component (i.e., channel) images, each for red, green, and blue. The pixel depth in RGB images determines the number of possible colours, with a typical full-colour image having a 24-bit depth (8 bits for each colour component). This allows for over 16 million possible colours. The RGB colour cube represents the range of colours achievable in this model, with the grayscale extending from black to white. The evolution of colour image processing reflects not only technological advancements but also a deepening understanding of colour science and its application in digital imaging.

Note: figures will be added!